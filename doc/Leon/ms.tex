% Every Latex document starts with a documentclass command
\documentclass[a4paper, 10pt]{article}

\usepackage{dsfont}
% Load some packages
\usepackage{graphicx} % This allows you to put figures in
\usepackage{natbib}   % This allows for relatively pain-free reference lists
\usepackage[left=3cm,top=3cm,right=3cm]{geometry} % The way I like the margins

% This helps with figure placement
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\parindent=0cm
\newcommand{\yy}{\mathbf{y}}
\newcommand{\mm}{\mathbf{m}_\theta}
\newcommand{\CC}{\mathbf{C}_\theta}

% Set values so you can have a title
\title{}
\author{}
\date{} % Otherwise, it'll show today's date

% Document starts here
\begin{document}
In this section we describe the Bayesian model used to infer the
time delay from the data. This model will be described in greater detail in
a forthcoming contribution (Brewer and Marshall, in prep).
Throughout this section we consider the measured signal in magnitudes,
rather than fluxes, as the model assumptions (Section~\ref{sec:assumptions})
make more sense in terms of magnitudes.

\section{The Data}
We denote the entire dataset (both images together)
as a vector of magnitude measurements:
\begin{eqnarray}
\yy = \{y_1, y_2, ..., y_N\}.
\end{eqnarray}
Along with these measurements we have the timestamps $\{t_i\}_{i=1}^N$,
error bars $\{\sigma_i\}_{i=1}^N$ and flags
$\{c_i\}_{i=1}^N$ where a flag $c_i \in \{A, B\}$ tells us whether the
measurement is of image $A$ or image $B$. The likelihood will be
written as a probability distribution for $\yy$ given some parameters, and the
timestamps, errorbars and flags will be considered as part of the prior
information.

\section{Model Assumptions}\label{sec:assumptions}
Suppose that the underlying QSO variability as a function
of time, as seen through image $A$, is described by the following function:
\begin{eqnarray}
y_{\rm QSO}(t)
\end{eqnarray}
Then the light curves of the two images
$A$ and $B$ will be given by:
\begin{eqnarray}
y_A(t) &=& M_A + y_{\rm QSO}(t)\\
y_B(t) &=& M_B + y_{\rm QSO}(t - \tau).
\end{eqnarray}
The light curve of image $A$ is just the underlying QSO variability,
and the light curve of 




plus a signal $\mu_A(t)$ that is due to microlensing or perhaps
other effects. The variability of image $B$ is given by
a lagged version of the QSO variability, plus another
perturbation $\mu_B(t)$ caused my microlensing.

The data are assumed to be noisy measurements of $y_A(t)$ and
$y_B(t)$ at various times. 

If we make the simplifying assumption that our prior knowledge about
$\mu_A(t)$, $\mu_B(t)$, and
$y_{\rm QSO}(t)$ can be described by Gaussian Processes \citep{rasmussen},
then the probability distribution for the data $\yy$ given the parameters
$\theta$
is a multivariate normal distribution, where the mean vector $\mm$
and the covariance matrix $\CC$ depend on the parameters:
\begin{eqnarray}
p(\yy | \theta) &=& \frac{1}{\sqrt{(2\pi)^N\det{\CC}}}
\exp\left[
-\frac{1}{2}
\left(
\yy - \mm
\right)^T
\CC^{-1}
\left(
\yy - \mm
\right)
\right]
\end{eqnarray}
The elements of the mean vector are just the mean magnitudes of the
appropriate images:
\begin{eqnarray}
m_i = M_{c_i}
\end{eqnarray}

The covariance matrix elements are given by:
\begin{eqnarray}
C_{ij} &=& \textnormal{Cov}(y_i, y_j) \\
&=& \mathds{E}\left[
\left(y_i - m_i\right)
\left(y_j - m_j\right)
\right]
\end{eqnarray}

We assume the following:
\begin{eqnarray}
\textnormal{Cov}\left(y_{\rm QSO}(t_1), y_{\rm QSO}(t_2)\right)
&=& \sigma_{\rm QSO}^2\exp\left[-\frac{\left|t_2 - t_1\right|}{L_{\rm QSO}}\right]
\end{eqnarray}

\begin{eqnarray}
\textnormal{Cov}\left(\mu_A(t_1), \mu_A(t_2)\right)
&=& \sigma_{{\rm ML}, A}^2\exp\left[-\left(\frac{\left|t_2 - t_1\right|}{L_{{\rm ML}, A}}\right)^\alpha\right]
\end{eqnarray}

\begin{eqnarray}
\textnormal{Cov}\left(\mu_B(t_1), \mu_B(t_2)\right)
&=& \sigma_{{\rm ML}, B}^2\exp\left[-\left(\frac{\left|t_2 - t_1\right|}{L_{{\rm ML}, B}}\right)^\alpha\right]
\end{eqnarray}

Numerically, the logarithm of the determinant and the
$\CC^{-1}\left(\yy - \mm\right)$ term are implemented using
Cholesky decompositions.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Parameter & Description & Prior\\
\hline
$\{m_k\}$ & Mean magnitudes & Uniform$(m_{\rm min}, m_{\rm max})$\\
$\{\tau_k\}$ & Time delays & Cauchy$(0, \tau_{\rm range}/10)T(\tau_{\rm min}, \tau_{\rm max})$\\
$\{\sigma_{\rm ML}\}$ & Standard deviations of microlensing signals & LogUniform$(\sigma_{\rm min}, \sigma_{\rm max})$\\
$\{L_{\rm ML}\}$ & Timescales of microlensing signals & LogUniform$(L_{\rm min}, L_{\rm max})$\\
$\alpha$ & Smoothness parameter for microlensing signals & Uniform$(1,2)$\\
$\sigma_{\rm QSO}$ & Standard deviation of quasar variability & LogUniform$(\sigma_{\rm min}, \sigma_{\rm max})$\\
$L_{\rm QSO}$ & Timescale of quasar variability & LogUniform$(L_{\rm min}, L_{\rm max})$\\
$f_{\rm bad}$ & Fraction of data points with incorrect errorbars & Uniform$(0,1)$\\
$K$ & Boost factor for bad errorbars & LogUniform$(1, 100)$\\
$\{b_i\}$ & Flag for whether each errorbar is bad & Bernoulli$(f_{\rm bad})$\\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{hist.pdf}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{error_bars.pdf}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[scale=0.7]{posterior_predictive_check.pdf}
\end{center}
\end{figure}

\begin{thebibliography}{99} 
\bibitem[\protect\citeauthoryear{Rasmussen \& Williams}{2006}]{rasmussen} Rasmussen C., Williams C., Gaussian Processes for Machine Learning, The MIT Press, 2006
\end{thebibliography}

\end{document}

